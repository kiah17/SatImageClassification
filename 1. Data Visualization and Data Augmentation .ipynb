{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import pickle\n",
    "import PIL.Image\n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "import skimage.io\n",
    "from skimage.filters import threshold_otsu\n",
    "from skimage.segmentation import clear_border\n",
    "from skimage.measure import label, regionprops\n",
    "from skimage.morphology import closing, square\n",
    "from skimage.color import label2rgb\n",
    "from skimage.transform import resize\n",
    "import matplotlib.patches as mpatches\n",
    "from skimage import data\n",
    "import skimage\n",
    "from skimage.transform import rotate\n",
    "\n",
    "import matplotlib as mpl\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "from matplotlib.ticker import LinearLocator, FormatStrFormatter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading dataset and extracting label information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data samples:  1604\n"
     ]
    }
   ],
   "source": [
    "train = json.loads(open('data/processed/train.json').read())\n",
    "print('Number of data samples: ',len(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_data(train):\n",
    "    '''\n",
    "    This function does the following: \n",
    "            1. The band 1 and band 2 pixel values are normalized \n",
    "            2. Plots the labels as a function of incidence angles. It can be seen that the data can \n",
    "               be divided into two groups as discussed in the kaggle winning model.It was checked that \n",
    "               the labels for all the images with 'na' incidence angles were 0 (not icebergs). Since \n",
    "               such a ship or a non-iceberg should belong to the patches that have a mixture of ships\n",
    "               and icebergs, a random incidence known angle that belongs to a ship is assigned to each\n",
    "               of the 'na' incidence angles. \n",
    "            3. The corresponding angles and labels (split into those with 'na' and without 'na') were \n",
    "               concatenated.\n",
    "    \n",
    "    Input: \n",
    "            1. The JSON dataset\n",
    "    \n",
    "    Output: \n",
    "            1. X_band1 - Band 1 pixel values (samples in rows, predictors in columns)\n",
    "            2. X_band2 - Band 2 pixel values (samples in rows, predictors in columns)\n",
    "            3. IS_ICEBERG - Labels for all images including 'na' incidence angles (Column Vector)\n",
    "            4. INC_ANGLES - Incidence angles for all images (Column Vector)\n",
    "    '''\n",
    "    \n",
    "    X_band1 = np.zeros((len(train),75*75))\n",
    "    X_band2 = np.zeros((len(train),75*75))\n",
    "    s = 0 \n",
    "    inc_angle = []\n",
    "    is_iceberg = []\n",
    "    for samp in train: \n",
    "        X_band1[s,:] = np.array(samp['band_1']).reshape(1,75*75)\n",
    "        X_band2[s,:] = np.array(samp['band_2']).reshape(1,75*75)\n",
    "        s+=1\n",
    "       \n",
    "        inc_angle.append(samp['inc_angle'])\n",
    "        is_iceberg.append(samp['is_iceberg'])\n",
    "        \n",
    "    #Output label and incident angles including 'na' \n",
    "    inc_angle = np.array(inc_angle).reshape(len(train),1)\n",
    "    is_iceberg = np.array(is_iceberg).reshape(len(train),1)\n",
    "    \n",
    "    #Normalizing the values for principal component analysis\n",
    "#     X_band1 = ((X_band1 - np.mean(X_band1,axis=1).reshape(75*75,1))/np.std(X_band1,axis =1)).reshape(X_band1.shape[0],X_band1.shape[1])\n",
    "#     X_band2 = ((X_band2 - np.mean(X_band2,axis=1).reshape(75*75,1))/np.std(X_band2,axis =1)).reshape(X_band2.shape[0],X_band2.shape[1])\n",
    "    \n",
    "    \n",
    "    #Samples for which incidence angle is given\n",
    "    inc_angle_number = np.where(inc_angle!='na')[0]\n",
    "    inc_angles_final = inc_angle[inc_angle_number]\n",
    "\n",
    "    #Labels only for the samples for which incidence angle is given\n",
    "    labels_inc_angle_number = is_iceberg[inc_angle_number]\n",
    "\n",
    "    #angles and labels\n",
    "    ang = []\n",
    "    lab = []\n",
    "    for c in range(0,len(inc_angles_final)):\n",
    "        ang.append(float(inc_angles_final[c][0]))\n",
    "        lab.append(labels_inc_angle_number[c].squeeze())\n",
    "\n",
    "    ang = np.array(ang)\n",
    "    lab = np.array(lab)\n",
    "    \n",
    "    #Plotting angles vs labels\n",
    "\n",
    "    plt.figure(figsize=(5,20))\n",
    "    for c in range(0,len(ang)): \n",
    "        if lab[c]==0:\n",
    "            plt.scatter(c,ang[c],marker='.',color='green')\n",
    "        else:\n",
    "            plt.scatter(c,ang[c],marker='.',color = 'red')\n",
    "\n",
    "    plt.ylim(ymin=30,ymax=max(ang))\n",
    "    plt.title('Variation of labels with incidence angles\\n Green: Ship\\n Red: Iceberg')\n",
    "    plt.xlabel('Sample number')\n",
    "    plt.ylabel('Incidence angle in degrees')\n",
    "    plt.savefig(\"inc_angle_labels.png\")\n",
    "    plt.show()\n",
    "    \n",
    "    #Filling NA values\n",
    "    #Indices in the inc_angle where it is na \n",
    "    inc_angle_na = np.where(inc_angle=='na')[0]\n",
    "\n",
    "    #All the labels with 'na' inc angle are ships\n",
    "    labels_inc_angle_na = is_iceberg[inc_angle_na]\n",
    "\n",
    "    ships_ang = inc_angle[np.where(is_iceberg==0)[0]]\n",
    "    ships_angles = ships_ang[np.where(ships_ang!='na')]\n",
    "\n",
    "    #All the 'na' incidence angles are ships. So we assign a random incidence angle of a random ship sample since ships belong to group 2. \n",
    "\n",
    "    #Assigning an angle to all the 'na' incidence angles\n",
    "    inc_angles_NA = []\n",
    "    for n_na in labels_inc_angle_na:\n",
    "\n",
    "        assign = np.random.randint(len(ships_angles))\n",
    "        inc_angles_NA.append(float(ships_angles[assign]))\n",
    "\n",
    "    inc_angles_NA = np.array(inc_angles_NA).reshape(len(inc_angle_na),1)\n",
    "\n",
    "    INC_ANGLES = np.vstack([ang.reshape(ang.shape[0],1),inc_angles_NA])\n",
    "    IS_ICEBERG =  np.vstack([lab.reshape(lab.shape[0],1),labels_inc_angle_na])\n",
    "    \n",
    "    return X_band1,X_band2,IS_ICEBERG,INC_ANGLES\n",
    "\n",
    "#Main \n",
    "X_band1,X_band2, is_iceberg, inc_angle = create_data(train)\n",
    "print('Shapes: \\n')\n",
    "print(X_band1.shape)\n",
    "print(X_band2.shape)\n",
    "print(is_iceberg.shape)\n",
    "print(inc_angle.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes: \n",
      "\n",
      "(3208, 5625)\n",
      "(3208, 5625)\n",
      "(3208, 1)\n",
      "(3208, 1)\n"
     ]
    }
   ],
   "source": [
    "def create_augment_data(X_band1,X_band2, is_iceberg, inc_angle):\n",
    "    '''\n",
    "    Input: \n",
    "        Output of the function create_data - \n",
    "            1. X_band1 - Band 1 pixel values (samples in rows, predictors in columns)\n",
    "            2. X_band2 - Band 2 pixel values (samples in rows, predictors in columns)\n",
    "            3. is_iceberg - Labels for all images including 'na' incidence angles (Column Vector)\n",
    "            4. inc_angles - Incidence angles for all images (Column Vector)\n",
    "    Output: \n",
    "            1. X_band1_final - Band 1 Concatenated original and augmented data (Samples in rows, \n",
    "               predictors in columns)\n",
    "            2. X_band2_final -  Band 2 Concatenated original and augmented data (Samples in rows, \n",
    "               predictors in columns)\n",
    "            3. IS_ICEBERG - Labels concatenated original and augmented data(Column Vector)\n",
    "            4. INC_ANGLES - Incidence angles original and augmented data (Column Vector)\n",
    "    '''\n",
    "    \n",
    "    X_band1_aug = np.zeros((len(train),75*75))\n",
    "    X_band2_aug = np.zeros((len(train),75*75))\n",
    "    \n",
    "    row = 0 \n",
    "    for samp in range(0,X_band1.shape[0]):\n",
    "        img1 = X_band1[samp].reshape(75,75)\n",
    "        img2 = X_band2[samp].reshape(75,75)\n",
    "\n",
    "        #Choose a random rotation angle between from 90,180,270 degrees\n",
    "        rot_angle = [90,180,270]\n",
    "        angle_ind = np.random.randint(0,3)\n",
    "        \n",
    "        img1_rot= rotate(img1,angle = rot_angle[angle_ind])\n",
    "        img2_rot = rotate(img2,angle = rot_angle[angle_ind])\n",
    "        \n",
    "        X_band1_aug[row,:] = img1_rot.reshape(1,75*75)\n",
    "        X_band2_aug[row,:] = img2_rot.reshape(1,75*75)\n",
    "        \n",
    "        row+=1\n",
    "    \n",
    "    #Normalizing the values for principal component analysis\n",
    "#     X_band1_aug = ((X_band1_aug - np.mean(X_band1_aug,axis=1).reshape(1,75*75))/np.std(X_band1_aug,axis =1)).reshape(X_band1_aug.shape[0],X_band1_aug.shape[1])\n",
    "#     X_band2_aug = ((X_band2_aug - np.mean(X_band2_aug,axis=1).reshape(1,75*75))/np.std(X_band2_aug,axis =1)).reshape(X_band2_aug.shape[0],X_band2_aug.shape[1])\n",
    "    \n",
    "    \n",
    "    #Band 1 and band 2 concatenation \n",
    "    X_band1_final = np.vstack([X_band1,X_band1_aug])\n",
    "    X_band2_final = np.vstack([X_band2,X_band2_aug])\n",
    "    \n",
    "    #Output labels concatenation\n",
    "    IS_ICEBERG = np.vstack([is_iceberg, is_iceberg])\n",
    "    \n",
    "    #Incidence angles concatenations\n",
    "    INC_ANGLES = np.vstack([inc_angle,inc_angle])\n",
    "    \n",
    "    return X_band1_final, X_band2_final, IS_ICEBERG, INC_ANGLES  \n",
    "\n",
    "\n",
    "#Main\n",
    "Xband1, Xband2, Y, A = create_augment_data(X_band1,X_band2, is_iceberg, inc_angle)\n",
    "\n",
    "print('Shapes: \\n')\n",
    "print(Xband1.shape)\n",
    "print(Xband2.shape)\n",
    "print(Y.shape)\n",
    "print(A.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting data into training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes: \n",
      "(2887, 5625)\n",
      "(2887, 5625)\n",
      "(2887, 1)\n",
      "(2887, 1)\n",
      "(321, 5625)\n",
      "(321, 5625)\n",
      "(321, 1)\n",
      "(321, 1)\n"
     ]
    }
   ],
   "source": [
    "def train_test_split(Xband1, Xband2, Y, A, test):\n",
    "    '''\n",
    "    Input: \n",
    "            1. Xband1 - Band 1 Original Feature Matrix (Final Augmented)\n",
    "            2. Xband2 - Band 2 Original Feature Matrix (Final Augmented)\n",
    "            3. Y - Output Label Vector \n",
    "            4. A - Incidence angles\n",
    "            5. test - Percentage of dataset for testing (between 0 and 1)\n",
    "    \n",
    "    Output: \n",
    "            1. X_band1_tr - Band 1 training set\n",
    "            2. X_band2_tr - Band 2 training set\n",
    "            3. X_band1_te - Band 1 testing set\n",
    "            4. X_band2_te - Band 2 testing set\n",
    "            5. Y_tr - Output label training set\n",
    "            6. Y_te - Output label test set\n",
    "            7. A_tr - Inc angles training\n",
    "            8. A_te - Inc angles testing set\n",
    "    '''\n",
    "    \n",
    "    rand = np.random.permutation(Xband1.shape[0])\n",
    "    \n",
    "    split_ind = int((1-test)*len(rand))\n",
    "\n",
    "    X_band1_tr = Xband1[rand[0:split_ind]]\n",
    "    X_band2_tr = Xband2[rand[0:split_ind]]\n",
    "    Y_tr = Y[rand[0:split_ind]]\n",
    "    A_tr = A[rand[0:split_ind]]\n",
    "    \n",
    "    X_band1_te = Xband1[rand[split_ind:]]\n",
    "    X_band2_te = Xband2[rand[split_ind:]]\n",
    "    Y_te = Y[rand[split_ind:]]\n",
    "    A_te = A[rand[split_ind:]]\n",
    "    \n",
    "    return(X_band1_tr,X_band2_tr,Y_tr,A_tr, X_band1_te,X_band2_te,Y_te, A_te)\n",
    "\n",
    "#Main\n",
    "X_band1_tr,X_band2_tr,Y_tr,A_tr, X_band1_te, X_band2_te, Y_te, A_te = train_test_split(Xband1, Xband2, Y, A,test=0.1)\n",
    "\n",
    "#Normalizing \n",
    "print('Shapes: ')\n",
    "print(X_band1_tr.shape)\n",
    "print(X_band2_tr.shape)\n",
    "print(Y_tr.shape)\n",
    "print(A_tr.shape)\n",
    "print(X_band1_te.shape)\n",
    "print(X_band2_te.shape)\n",
    "print(Y_te.shape)\n",
    "print(A_te.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Saving\n",
    "\n",
    "np.save('aug_data_split/Xb1_tr.npy',X_band1_tr)\n",
    "np.save('aug_data_split/Xb2_tr.npy',X_band2_tr)\n",
    "np.save('aug_data_split/Y_tr.npy',Y_tr)\n",
    "np.save('aug_data_split/A_tr.npy',A_tr)\n",
    "np.save('aug_data_split/Xb1_te.npy',X_band1_te)\n",
    "np.save('aug_data_split/Xb2_te.npy',X_band2_te)\n",
    "np.save('aug_data_split/Y_te.npy',Y_te)\n",
    "np.save('aug_data_split/A_te.npy',A_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
